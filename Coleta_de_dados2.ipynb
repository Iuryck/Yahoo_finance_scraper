{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta de dados da Bovespa parte 2\n",
    "\n",
    "**Agora vamos tentar coletar dados além dos dados da bolsa por si só. Dados como margem de lucro, gastos, dividendos e etc. Dados em respeito a parte financeira das empresas.**\n",
    "\n",
    "**Vamos coletar os dados do site Yahoo finance, usamos BeautifulSoup e PandasDataReader para fazer \"Web Scraping\" do site. Usamos algumas ações individualmente como exemplo.**\n",
    "\n",
    "**Para entender melhor o que está sendo feito, recomendo que abra os links usados para webscraping e acompanhar com o código.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas usadas\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "import requests\n",
    "import bs4 as bs\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt \n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos começar lendo dados de finanças da B3SA3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-62af989b171c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Lendo o site das finanças da empresa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mread\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://finance.yahoo.com/quote/B3SA3.SA/financials'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m         \u001b[0mraise_with_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretained\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[1;34m(exc, traceback)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "#Lendo o site das finanças da empresa\n",
    "read = pd.read_html('https://finance.yahoo.com/quote/B3SA3.SA/financials')\n",
    "print(read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esse site nao possui tabelas, portanto teremos que usar beautifulSoup para explorar os dados mostrados no site. BeatifulSoup explora o código fonte de páginas e facilita extração de dados dela**\n",
    "\n",
    "**Vamos ler o site em formato txt e mostrar todas as linhas da classe \"span\" onde estão os dados que queremos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span data-reactid=\"31\">No matching results for ''</span>\n",
      "<span data-reactid=\"33\">Tip: Try a valid symbol or a specific company name for relevant results</span>\n",
      "<span data-reactid=\"36\">Cancel</span>\n",
      "<span data-reactid=\"9\">Summary</span>\n",
      "<span data-reactid=\"13\">Statistics</span>\n",
      "<span data-reactid=\"17\">Historical Data</span>\n",
      "<span data-reactid=\"21\">Profile</span>\n",
      "<span data-reactid=\"25\">Financials</span>\n",
      "<span data-reactid=\"29\">Analysis</span>\n",
      "<span data-reactid=\"33\">Options</span>\n",
      "<span data-reactid=\"37\">Holders</span>\n",
      "<span data-reactid=\"41\">Sustainability</span>\n",
      "<span data-reactid=\"9\">Sao Paolo - Sao Paolo Delayed Price. Currency in BRL</span>\n",
      "<span class=\"Mend(10px) smartphone_D(n)\" data-reactid=\"5\"><span data-reactid=\"6\">Show</span><!-- react-text: 7 -->:<!-- /react-text --></span>\n",
      "<span data-reactid=\"6\">Show</span>\n",
      "<span data-reactid=\"10\">Income Statement</span>\n",
      "<span data-reactid=\"13\">Balance Sheet</span>\n",
      "<span data-reactid=\"16\">Cash Flow</span>\n",
      "<span data-reactid=\"19\">Annual</span>\n",
      "<span data-reactid=\"22\">Income Statement</span>\n",
      "<span class=\"Fz(xs) C($tertiaryColor) Mstart(25px) smartphone_Mstart(0px) smartphone_D(b) smartphone_Mt(5px)\" data-reactid=\"23\"><span data-reactid=\"24\">All numbers in thousands</span></span>\n",
      "<span data-reactid=\"24\">All numbers in thousands</span>\n",
      "<span data-reactid=\"31\">Breakdown</span>\n",
      "<span data-reactid=\"34\">ttm</span>\n",
      "<span data-reactid=\"36\">12/30/2019</span>\n",
      "<span data-reactid=\"38\">12/30/2018</span>\n",
      "<span data-reactid=\"40\">12/30/2017</span>\n",
      "<span data-reactid=\"42\">12/30/2016</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"48\">Total Revenue</span>\n",
      "<span data-reactid=\"51\">6,576,507</span>\n",
      "<span data-reactid=\"53\">6,576,507</span>\n",
      "<span data-reactid=\"55\">4,831,915</span>\n",
      "<span data-reactid=\"57\">3,673,596</span>\n",
      "<span data-reactid=\"59\">2,320,781</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"65\">Cost of Revenue</span>\n",
      "<span data-reactid=\"68\">1,267,869</span>\n",
      "<span data-reactid=\"70\">1,267,869</span>\n",
      "<span data-reactid=\"72\">921,531</span>\n",
      "<span data-reactid=\"74\">810,851</span>\n",
      "<span data-reactid=\"76\">649,753</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"82\">Gross Profit</span>\n",
      "<span data-reactid=\"85\">5,308,638</span>\n",
      "<span data-reactid=\"87\">5,308,638</span>\n",
      "<span data-reactid=\"89\">3,910,384</span>\n",
      "<span data-reactid=\"91\">2,862,745</span>\n",
      "<span data-reactid=\"93\">1,671,028</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"102\">Operating Expenses</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"115\">Selling General and Administrative</span>\n",
      "<span data-reactid=\"118\">35,880</span>\n",
      "<span data-reactid=\"120\">35,880</span>\n",
      "<span data-reactid=\"122\">35,354</span>\n",
      "<span data-reactid=\"124\">32,290</span>\n",
      "<span data-reactid=\"126\">17,669</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"132\">Total Operating Expenses</span>\n",
      "<span data-reactid=\"135\">2,105,710</span>\n",
      "<span data-reactid=\"137\">2,105,710</span>\n",
      "<span data-reactid=\"139\">1,472,223</span>\n",
      "<span data-reactid=\"141\">1,083,073</span>\n",
      "<span data-reactid=\"143\">562,842</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"149\">Operating Income or Loss</span>\n",
      "<span data-reactid=\"152\">3,202,928</span>\n",
      "<span data-reactid=\"154\">3,202,928</span>\n",
      "<span data-reactid=\"156\">2,438,161</span>\n",
      "<span data-reactid=\"158\">1,779,672</span>\n",
      "<span data-reactid=\"160\">1,108,186</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"166\">Interest Expense</span>\n",
      "<span data-reactid=\"169\">315,548</span>\n",
      "<span data-reactid=\"171\">315,548</span>\n",
      "<span data-reactid=\"173\">371,902</span>\n",
      "<span data-reactid=\"175\">482,486</span>\n",
      "<span data-reactid=\"177\">152,093</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"184\">Income Before Tax</span>\n",
      "<span data-reactid=\"187\">3,339,046</span>\n",
      "<span data-reactid=\"189\">3,339,046</span>\n",
      "<span data-reactid=\"191\">2,338,409</span>\n",
      "<span data-reactid=\"193\">1,577,709</span>\n",
      "<span data-reactid=\"195\">1,246,570</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"201\">Income Tax Expense</span>\n",
      "<span data-reactid=\"204\">625,842</span>\n",
      "<span data-reactid=\"206\">625,842</span>\n",
      "<span data-reactid=\"208\">250,058</span>\n",
      "<span data-reactid=\"210\">281,064</span>\n",
      "<span data-reactid=\"212\">-199,494</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"218\">Income from Continuing Operations</span>\n",
      "<span data-reactid=\"221\">2,713,204</span>\n",
      "<span data-reactid=\"223\">2,713,204</span>\n",
      "<span data-reactid=\"225\">2,088,351</span>\n",
      "<span data-reactid=\"227\">1,296,645</span>\n",
      "<span data-reactid=\"229\">1,446,064</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"235\">Net Income</span>\n",
      "<span data-reactid=\"238\">2,714,166</span>\n",
      "<span data-reactid=\"240\">2,714,166</span>\n",
      "<span data-reactid=\"242\">2,087,444</span>\n",
      "<span data-reactid=\"244\">1,296,240</span>\n",
      "<span data-reactid=\"246\">1,446,263</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"252\">Net Income available to common shareholders</span>\n",
      "<span data-reactid=\"255\">2,714,166</span>\n",
      "<span data-reactid=\"257\">2,714,166</span>\n",
      "<span data-reactid=\"259\">2,087,444</span>\n",
      "<span data-reactid=\"261\">1,296,240</span>\n",
      "<span data-reactid=\"263\">1,446,263</span>\n",
      "<span class=\"Va(m)\" data-reactid=\"271\">EBITDA</span>\n",
      "<span data-reactid=\"275\">4,684,844</span>\n",
      "<span data-reactid=\"277\">3,663,416</span>\n",
      "<span data-reactid=\"279\">2,775,755</span>\n",
      "<span data-reactid=\"281\">1,496,984</span>\n",
      "<span data-reactid=\"2\"></span>\n",
      "<span data-reactid=\"2\"></span>\n",
      "<span data-reactid=\"2\"></span>\n",
      "<span data-reactid=\"7\">Data Disclaimer</span>\n",
      "<span data-reactid=\"9\">Help</span>\n",
      "<span data-reactid=\"11\">Suggestions</span>\n",
      "<span data-reactid=\"15\">Privacy (Updated)</span>\n",
      "<span data-reactid=\"17\">About Our Ads</span>\n",
      "<span data-reactid=\"19\">Terms (Updated)</span>\n",
      "<span data-reactid=\"21\">Sitemap</span>\n",
      "<span class=\"C($grey6)\" data-reactid=\"38\"><span data-reactid=\"39\">© 2020 Verizon Media. All rights reserved.</span></span>\n",
      "<span data-reactid=\"39\">© 2020 Verizon Media. All rights reserved.</span>\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('https://finance.yahoo.com/quote/B3SA3.SA/financials')\n",
    "#BeautifulSoup faz o scrape do codigo fonte da pagina em TXT\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "#Quantidade de linhas escrito span\n",
    "length = np.array(soup.find_all('span')).shape[0]\n",
    "\n",
    "#Vetor com as linhas escrito span\n",
    "lines = np.array(soup.find_all('span'))\n",
    "\n",
    "#Lista para armazenar as linhas da classe span, pra não precisar usar \"BeautifulSoup(str(lines[line])).span\" toda hora\n",
    "spans = []\n",
    "\n",
    "for line in range(0,length):\n",
    "    \n",
    "    #Armazenando e mostrando as linhas\n",
    "    spans.append(BeautifulSoup(str(lines[line])).span)\n",
    "    print(BeautifulSoup(str(lines[line])).span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O que faremos então, é extrair o \"react id\" e o texto de cada linha, tomamos nota de qual ID se refere a que informação, e pegamos as que queremos. Para isso é necessário olhar o site e comparar os dados.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 - No matching results for ''\n",
      "33 - Tip: Try a valid symbol or a specific company name for relevant results\n",
      "36 - Cancel\n",
      "9 - Summary\n",
      "13 - Statistics\n",
      "17 - Historical Data\n",
      "21 - Profile\n",
      "25 - Financials\n",
      "29 - Analysis\n",
      "33 - Options\n",
      "37 - Holders\n",
      "41 - Sustainability\n",
      "9 - Sao Paolo - Sao Paolo Delayed Price. Currency in BRL\n",
      "5 - None\n",
      "6 - Show\n",
      "10 - Income Statement\n",
      "13 - Balance Sheet\n",
      "16 - Cash Flow\n",
      "19 - Annual\n",
      "22 - Income Statement\n",
      "23 - All numbers in thousands\n",
      "24 - All numbers in thousands\n",
      "31 - Breakdown\n",
      "34 - ttm\n",
      "36 - 12/30/2019\n",
      "38 - 12/30/2018\n",
      "40 - 12/30/2017\n",
      "42 - 12/30/2016\n",
      "48 - Total Revenue\n",
      "51 - 6,576,507\n",
      "53 - 6,576,507\n",
      "55 - 4,831,915\n",
      "57 - 3,673,596\n",
      "59 - 2,320,781\n",
      "65 - Cost of Revenue\n",
      "68 - 1,267,869\n",
      "70 - 1,267,869\n",
      "72 - 921,531\n",
      "74 - 810,851\n",
      "76 - 649,753\n",
      "82 - Gross Profit\n",
      "85 - 5,308,638\n",
      "87 - 5,308,638\n",
      "89 - 3,910,384\n",
      "91 - 2,862,745\n",
      "93 - 1,671,028\n",
      "102 - Operating Expenses\n",
      "115 - Selling General and Administrative\n",
      "118 - 35,880\n",
      "120 - 35,880\n",
      "122 - 35,354\n",
      "124 - 32,290\n",
      "126 - 17,669\n",
      "132 - Total Operating Expenses\n",
      "135 - 2,105,710\n",
      "137 - 2,105,710\n",
      "139 - 1,472,223\n",
      "141 - 1,083,073\n",
      "143 - 562,842\n",
      "149 - Operating Income or Loss\n",
      "152 - 3,202,928\n",
      "154 - 3,202,928\n",
      "156 - 2,438,161\n",
      "158 - 1,779,672\n",
      "160 - 1,108,186\n",
      "166 - Interest Expense\n",
      "169 - 315,548\n",
      "171 - 315,548\n",
      "173 - 371,902\n",
      "175 - 482,486\n",
      "177 - 152,093\n",
      "184 - Income Before Tax\n",
      "187 - 3,339,046\n",
      "189 - 3,339,046\n",
      "191 - 2,338,409\n",
      "193 - 1,577,709\n",
      "195 - 1,246,570\n",
      "201 - Income Tax Expense\n",
      "204 - 625,842\n",
      "206 - 625,842\n",
      "208 - 250,058\n",
      "210 - 281,064\n",
      "212 - -199,494\n",
      "218 - Income from Continuing Operations\n",
      "221 - 2,713,204\n",
      "223 - 2,713,204\n",
      "225 - 2,088,351\n",
      "227 - 1,296,645\n",
      "229 - 1,446,064\n",
      "235 - Net Income\n",
      "238 - 2,714,166\n",
      "240 - 2,714,166\n",
      "242 - 2,087,444\n",
      "244 - 1,296,240\n",
      "246 - 1,446,263\n",
      "252 - Net Income available to common shareholders\n",
      "255 - 2,714,166\n",
      "257 - 2,714,166\n",
      "259 - 2,087,444\n",
      "261 - 1,296,240\n",
      "263 - 1,446,263\n",
      "271 - EBITDA\n",
      "275 - 4,684,844\n",
      "277 - 3,663,416\n",
      "279 - 2,775,755\n",
      "281 - 1,496,984\n",
      "2 - None\n",
      "2 - None\n",
      "2 - None\n",
      "7 - Data Disclaimer\n",
      "9 - Help\n",
      "11 - Suggestions\n",
      "15 - Privacy (Updated)\n",
      "17 - About Our Ads\n",
      "19 - Terms (Updated)\n",
      "21 - Sitemap\n",
      "38 - © 2020 Verizon Media. All rights reserved.\n",
      "39 - © 2020 Verizon Media. All rights reserved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for line in range(0,length):\n",
    "   \n",
    "    print(f\"{spans[line]['data-reactid']} - {spans[line].string}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se quisermos aplicar essa coleta de dados a todas as ações da bovespa, o algoritmo precisa adaptar ao site, coletando apenas o que o site possui de informações. Vamos usar a ação NTCO3 da natura, que possui dados apenas de 2019, para mostrar de exemplo a coleta de dados quando temos diferentes quantidades de datas para os dados.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 - No matching results for ''\n",
      "33 - Tip: Try a valid symbol or a specific company name for relevant results\n",
      "36 - Cancel\n",
      "9 - Summary\n",
      "13 - Statistics\n",
      "17 - Historical Data\n",
      "21 - Profile\n",
      "25 - Financials\n",
      "29 - Analysis\n",
      "33 - Options\n",
      "37 - Holders\n",
      "41 - Sustainability\n",
      "9 - Sao Paolo - Sao Paolo Delayed Price. Currency in BRL\n",
      "5 - None\n",
      "6 - Show\n",
      "10 - Income Statement\n",
      "13 - Balance Sheet\n",
      "16 - Cash Flow\n",
      "19 - Annual\n",
      "22 - Income Statement\n",
      "23 - All numbers in thousands\n",
      "24 - All numbers in thousands\n",
      "31 - Breakdown\n",
      "34 - ttm\n",
      "36 - 12/30/2019\n",
      "42 - Total Revenue\n",
      "45 - 14,444,700\n",
      "47 - 14,444,700\n",
      "53 - Cost of Revenue\n",
      "56 - 4,033,500\n",
      "58 - 4,033,500\n",
      "64 - Gross Profit\n",
      "67 - 10,411,200\n",
      "69 - 10,411,200\n",
      "78 - Operating Expenses\n",
      "88 - Selling General and Administrative\n",
      "91 - 8,801,200\n",
      "93 - 8,801,200\n",
      "99 - Total Operating Expenses\n",
      "102 - 9,057,100\n",
      "104 - 9,057,100\n",
      "110 - Operating Income or Loss\n",
      "113 - 1,354,100\n",
      "115 - 1,354,100\n",
      "121 - Interest Expense\n",
      "124 - 2,795,900\n",
      "126 - 2,795,900\n",
      "132 - Total Other Income/Expenses Net\n",
      "135 - -209,500\n",
      "137 - -209,500\n",
      "143 - Income Before Tax\n",
      "146 - 304,600\n",
      "148 - 304,600\n",
      "154 - Income Tax Expense\n",
      "157 - 149,100\n",
      "159 - 149,100\n",
      "165 - Income from Continuing Operations\n",
      "168 - 155,500\n",
      "170 - 155,500\n",
      "176 - Net Income\n",
      "179 - 155,500\n",
      "181 - 155,500\n",
      "187 - Net Income available to common shareholders\n",
      "190 - 155,500\n",
      "192 - 155,500\n",
      "200 - EBITDA\n",
      "204 - 3,100,500\n",
      "2 - None\n",
      "2 - None\n",
      "2 - None\n",
      "7 - Data Disclaimer\n",
      "9 - Help\n",
      "11 - Suggestions\n",
      "15 - Privacy (Updated)\n",
      "17 - About Our Ads\n",
      "19 - Terms (Updated)\n",
      "21 - Sitemap\n",
      "38 - © 2020 Verizon Media. All rights reserved.\n",
      "39 - © 2020 Verizon Media. All rights reserved.\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('https://finance.yahoo.com/quote/NTCO3.SA/financials')\n",
    "#BeautifulSoup faz o scrape do codigo fonte da pagina em TXT\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "#pegando a quantidade de linhas Span no site\n",
    "length = np.array(soup.find_all('span')).shape[0]\n",
    "\n",
    "#Vetor com todas as linhas da classe span do site \n",
    "lines = np.array(soup.find_all('span'))\n",
    "\n",
    "#Lista que vamos aramzenar as linhas da classe span \n",
    "spans = []\n",
    "\n",
    "#Pegando as linhas\n",
    "for line in range(0,length):\n",
    "    spans.append(BeautifulSoup(str(lines[line])).span)\n",
    "   \n",
    "#Mostrando as linhas\n",
    "for line in range(0,length):\n",
    "   \n",
    "    print(f\"{spans[line]['data-reactid']} - {spans[line].string}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12/30/2019']\n"
     ]
    }
   ],
   "source": [
    "#Datas que queremos encontrar no site\n",
    "find_dates = ['12/30/2019','12/30/2018','12/30/2017','12/30/2016']\n",
    "\n",
    "#Lista para as datas que realmente achamos no site\n",
    "dates = []\n",
    "\n",
    "\n",
    "resp = requests.get('https://finance.yahoo.com/quote/NTCO3.SA/financials')\n",
    "#BeautifulSoup faz o scrape do codigo fonte da pagina em TXT\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "#pegando a quantidade de linhas Span no site\n",
    "length = np.array(soup.find_all('span')).shape[0]\n",
    "\n",
    "#Vetor com todas as linhas da classe span do site \n",
    "lines = np.array(soup.find_all('span'))\n",
    "\n",
    "#Lista que vamos aramzenar as linhas da classe span \n",
    "spans = []\n",
    "\n",
    "#Pegando as linhas\n",
    "for line in range(0,length):\n",
    "    spans.append(BeautifulSoup(str(lines[line])).span)\n",
    "\n",
    "#Iterando pelas datas que queremos achar \n",
    "for date in find_dates:\n",
    "    \n",
    "    #Iterando pelas linhas\n",
    "    for line in range(0,length):\n",
    "        \n",
    "        #Caso o texto da linha corresponde a uma data que queremos, ela é adicionada a lista de datas\n",
    "        if spans[line].string == date:\n",
    "            dates.append(spans[line].string)\n",
    "            break\n",
    "            \n",
    "\n",
    "        \n",
    "print(dates)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agora usaremos a mesma lógica para achar os dados que queremos. E vamos usar a ação ITSA4 para demonstrar a coleta de dados em caso de ter menos informações que o esperado.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Total Revenue', 'Selling General and Administrative', 'Total Operating Expenses', 'Interest Expense', 'Income Before Tax', 'Income Tax Expense', 'Income from Continuing Operations', 'Net Income', 'Net Income available to common shareholders']\n"
     ]
    }
   ],
   "source": [
    "#Informações que queremos encontrar\n",
    "interesting_lines =['Total Revenue',\n",
    "                     'Cost of Revenue',\n",
    "                     'Gross Profit',\n",
    "                     'Selling General and Administrative',\n",
    "                     'Total Operating Expenses',\n",
    "                     'Operating Income or Loss',\n",
    "                     'Interest Expense',\n",
    "                     'Income Before Tax',\n",
    "                     'Income Tax Expense',\n",
    "                     'Income from Continuing Operations',\n",
    "                     'Net Income',\n",
    "                     'Net Income available to common shareholders',\n",
    "                     'EBITDA']\n",
    "#Lista para informações que realmente encontramos no site\n",
    "infos = []\n",
    "\n",
    "#Lista para o ReactID dos dados sobre as informações que queremos\n",
    "data_ids = []\n",
    "\n",
    "resp = requests.get('https://finance.yahoo.com/quote/ITSA4.SA/financials')\n",
    "#BeautifulSoup faz o scrape do codigo fonte da pagina em TXT\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "#pegando a quantidade de linhas Span no site\n",
    "length = np.array(soup.find_all('span')).shape[0]\n",
    "\n",
    "#Vetor com todas as linhas da classe span do site \n",
    "lines = np.array(soup.find_all('span'))\n",
    "\n",
    "#Lista que vamos aramzenar as linhas da classe span \n",
    "spans = []\n",
    "\n",
    "#Pegando as linhas\n",
    "for line in range(0,length):\n",
    "    spans.append(BeautifulSoup(str(lines[line])).span)\n",
    "\n",
    "#Iterando pelas informações que esperamos encontrar\n",
    "for info in interesting_lines:\n",
    "    \n",
    "    #Iteramdo pelas linhas de classe span\n",
    "    for line in range(0,length):\n",
    "        \n",
    "        '''\n",
    "        Se olharmos a lista de linhas Span veremos que os dados de cada informação fica embaixo do nome da informação.\n",
    "        Então vamos achar a linha que possui o nome da informação, pular 2 linhas e retirar o reactID dessa linha. Que\n",
    "        será a linha equivalente aos dados em 30/12/2019 da tal informação.\n",
    "        \n",
    "        '''\n",
    "        if spans[line].string == info:\n",
    "            \n",
    "            #Pegando a informação encontrada\n",
    "            infos.append(spans[line].string)\n",
    "            \n",
    "            #Pegando o reactID dos dados da mesma informação\n",
    "            data_ids.append( str(int(spans[line]['data-reactid'])+3) )\n",
    "            break\n",
    "            \n",
    "print(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['51', '86', '103', '121', '136', '153', '170', '187', '204']\n"
     ]
    }
   ],
   "source": [
    "print(data_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aqui está um pequeno exemplo de como o script ficará até agora. Isso será usado em loop para iterar pelas várias ações da BOVESPA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Testing stock: ITSA4.SA - Source: yahoo\n",
      ">>>Getting Stock Data from yahoo from 2020-03-17\n",
      ">>>Prepring Plot\n",
      "['Total Revenue (TTM)', 'Selling General and Administrative Expenses (TTM)', 'Total Operating Expenses (TTM)', 'Interest Expense (TTM)', 'Income Before Tax (TTM)', 'Income Tax Expense (TTM)', 'Income from Coninuing Operations (TTM)', 'Net Income (TTM)', 'Net Income available to Shareholders (TTM)']\n"
     ]
    }
   ],
   "source": [
    "#//////////////////////////////////////////////\n",
    "\n",
    "\n",
    "# \"NTCO3.SA\" para testar com menos datas \"ITSA4.SA\" para testar menos colunas\n",
    "\n",
    "ticker = 'ITSA4.SA'\n",
    "\n",
    "source = 'yahoo'\n",
    "\n",
    "rsi_period = 14 #days\n",
    "\n",
    "#/////////////////////////////////////////////\n",
    "\n",
    "print(f'>>> Testing stock: {ticker} - Source: {source}')\n",
    "\n",
    "# When data collecting will start and end for the Dates\n",
    "start = dt.datetime(2007,1,1)\n",
    "end = (dt.datetime.now() - dt.timedelta(1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "print(f'>>>Getting Stock Data from {source} from {end}')\n",
    "\n",
    "\n",
    "\n",
    "df = web.DataReader(ticker, source, start, end)\n",
    "\n",
    "\n",
    "\n",
    "#Boolinger Band\n",
    "df['Close_MA'] =   df['Adj Close'].rolling(20).mean()\n",
    "df['Sup_band'] =  df['Close_MA'] + (2*df['Adj Close'].rolling(20).std())\n",
    "df['Inf_band'] =  df['Close_MA'] - (2*df['Adj Close'].rolling(20).std())\n",
    "\n",
    "#Exponential Moving Mean\n",
    "df['Exp20_Close'] = df['Adj Close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "#Expantion/Contraction de boolinger bands\n",
    "df['Subtract_band'] = df['Adj Close'].rolling(20).std()\n",
    "\n",
    "\n",
    "#RSI\n",
    "change = df['Adj Close'].diff(1)\n",
    "\n",
    "gain = change.mask(change<0, 0)\n",
    "loss = change.mask(change>0, 0)\n",
    "avg_gain = gain.ewm(min_periods=rsi_period, com=rsi_period-1).mean()\n",
    "avg_loss = loss.ewm(min_periods=rsi_period, com=rsi_period-1).mean()\n",
    "rs = abs(avg_gain / avg_loss)\n",
    "df['RSI'] = 100 - (100/(1+rs))\n",
    "\n",
    "\n",
    "#Datas que queremos achar\n",
    "find_dates = ['12/30/2019','12/30/2018','12/30/2017','12/30/2016']\n",
    "\n",
    "#Lista para as datas que achamos\n",
    "dates = []\n",
    "\n",
    "resp = requests.get(f'https://finance.yahoo.com/quote/{ticker}/financials')\n",
    "#BeautifulSoup faz o scrape do codigo fonte da pagina em TXT\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "#Quantas linhas da classe Span existe\n",
    "length = np.array(soup.find_all('span')).shape[0]\n",
    "\n",
    "#Vetor para armazenar as linhas escrito Span\n",
    "lines = np.array(soup.find_all('span'))\n",
    "\n",
    "#Lista para armazenar as linhas classe Span, para não precisar usar \"BeautifulSoup(str(lines[line])).span\" toda hora\n",
    "spans = []\n",
    "\n",
    "#Iterando pelas linhas no vetor armazenando as linhas classe Span\n",
    "for line in range(0,length):\n",
    "    spans.append(BeautifulSoup(str(lines[line])).span)\n",
    "\n",
    "#Iterando pelas datas que queremos encontrar\n",
    "for date in find_dates:\n",
    "    \n",
    "    #Iterando pelas linhas Span\n",
    "    for line in range(0,length):\n",
    "        \n",
    "        #Se a linha tiver uma data que queremos, ela é adicionada as linhas que queremos encontrar\n",
    "        if spans[line].string == date:\n",
    "            dates.append(spans[line].string)\n",
    "            break\n",
    "            \n",
    "#Iterando pelas datas que encontramos\n",
    "for index, date in enumerate(dates): \n",
    "    \n",
    "    #Mudando a formatação das datas, para encaixar com as datas do pandas webreader\n",
    "    try:\n",
    "        dates[index] = dt.datetime.strptime(date, \"%m/%d/%Y\").strftime(\"%Y-%m-%d\") \n",
    "    \n",
    "    #Se der erro na formatação é porque não se trata de uma data, então se faz um loop até esse\n",
    "    #conteúdo ser removido por completo da lista\n",
    "    except:\n",
    "        removed = False\n",
    "        while(removed == False):\n",
    "            \n",
    "            #dates.remove vai desparar um erro caso não tenha mais esse conteúdo na lista, assim encerrando o loop\n",
    "            try:\n",
    "                dates.remove(dates[index]) \n",
    "            except:\n",
    "                removed = True\n",
    "                \n",
    "                \n",
    "#Adicionando 3 dias nas datas porque a bolsa não opera nesse último dia de ano            \n",
    "for index, date in enumerate(dates):\n",
    "    dates[index] = (dt.datetime.strptime(date, '%Y-%m-%d') + dt.timedelta(3)).strftime('%Y-%m-%d')\n",
    "                \n",
    "                \n",
    "#As informações que queremos encontrar     \n",
    "interesting_lines =['Total Revenue',\n",
    "                     'Cost of Revenue',\n",
    "                     'Gross Profit',\n",
    "                     'Selling General and Administrative',\n",
    "                     'Total Operating Expenses',\n",
    "                     'Operating Income or Loss',\n",
    "                     'Interest Expense',\n",
    "                     'Income Before Tax',\n",
    "                     'Income Tax Expense',\n",
    "                     'Income from Continuing Operations',\n",
    "                     'Net Income',\n",
    "                     'Net Income available to common shareholders',\n",
    "                     'EBITDA']\n",
    "\n",
    "#Lista para as informações que achamos\n",
    "infos = []\n",
    "\n",
    "#Lista para os ReactID das informações que encontramos \n",
    "number_ids = []\n",
    "\n",
    "#Renomeando as colunas para colocar no arquivo final\n",
    "column_names=['Total Revenue (TTM)',\n",
    "           'Cost of Revenue (TTM)',\n",
    "           'Gross Profit (TTM)',\n",
    "           'Selling General and Administrative Expenses (TTM)',\n",
    "           'Total Operating Expenses (TTM)',\n",
    "           'Operating Income or Loss (TTM)',\n",
    "           'Interest Expense (TTM)',\n",
    "           'Income Before Tax (TTM)',\n",
    "           'Income Tax Expense (TTM)',\n",
    "           'Income from Coninuing Operations (TTM)',\n",
    "           'Net Income (TTM)',\n",
    "           'Net Income available to Shareholders (TTM)',\n",
    "           'EBITDA (TTM)']        \n",
    "\n",
    "\n",
    "#Iterando pelas informações que queremos \n",
    "for index, info in enumerate(interesting_lines):\n",
    "    \n",
    "    #Booleano para se a informação foi encontrada\n",
    "    check = False\n",
    "    \n",
    "    #Iterando pelas linhas do site\n",
    "    for line in range(0,length):\n",
    "        \n",
    "        #Se a linha tiver a informação que queremos adicionamos ela a lista de encontrados\n",
    "        if spans[line].string == info:\n",
    "            infos.append(spans[line].string)\n",
    "            \n",
    "            #E pegamos a linha abaixo que possui os números a respeito da informação\n",
    "            number_ids.append(str(int(spans[line]['data-reactid'])+5))\n",
    "            check = True\n",
    "            pass\n",
    "    \n",
    "    #Caso não encontrado, a informação na lista de colunas renomeadas vira um NAN\n",
    "    if check == False:\n",
    "        column_names[index] = np.nan\n",
    "            \n",
    "    \n",
    "#Removendo NANs da lista de colunas\n",
    "column_names = [c for c in column_names if str(c) != 'nan']   \n",
    "\n",
    "\n",
    "\n",
    "#Criando as novas colunas\n",
    "for column in column_names:\n",
    "    df[f'{column}'] = np.nan\n",
    "    \n",
    "#Iterando pelas datas com indexação\n",
    "for index, date in enumerate(dates):   \n",
    "            \n",
    "    #Iterando pelas colunas com indexação\n",
    "    for column, string in enumerate(column_names):\n",
    "                \n",
    "        #Iterando pelas linhas span\n",
    "        for line in range(0,length):\n",
    "                    \n",
    "            #Pegando os dados para a respectativa coluna em ordem. Com base no ReactID que pegamos antes\n",
    "            if spans[line]['data-reactid'] == number_ids[column]:\n",
    "                 \n",
    "                #Localiza a data no índice do Dataframe, formata o texto dos dados, transforma em número Integer, e então\n",
    "                #aloca os dados na sua coluna e respectiva data \n",
    "                try:\n",
    "                    df[f'{string}'].loc[dates[index]] = int((spans[line].string).replace(',',''))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print (f'Error formating/alocating string to int for stock {ticker}')\n",
    "                    continue      \n",
    "    \n",
    "    \n",
    "    #Adiciona 2 aos ReactIDs para pegar os dados das datas anteriores\n",
    "    number_ids = [int(c) for c in number_ids]\n",
    "    number_ids = [c+2 for c in number_ids]\n",
    "    number_ids = [str(c) for c in number_ids]\n",
    "\n",
    "        \n",
    "'''\n",
    "Como a função .loc só aloca os dados na fileira da respectiva data, as outras linhas vão ficar com NANs. Pra mudar isso \n",
    "usamos o método ffill para usar esses dados alocados para preencher todos os NANs futuros até encontrar o próximo valor ou\n",
    "o valor mais recente, e então usa esse novo dado para preencher as próximas fileiras.\n",
    "''' \n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mostrando os dados de cada coluna para cada respectivo dia encontrado no site, mostrando que foram alocados de acordo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "14.380000114440918\n",
      "Low\n",
      "14.069999694824219\n",
      "Open\n",
      "14.140000343322754\n",
      "Close\n",
      "14.350000381469727\n",
      "Volume\n",
      "18284800.0\n",
      "Adj Close\n",
      "14.081748962402344\n",
      "Close_MA\n",
      "13.517823553085327\n",
      "Sup_band\n",
      "14.072112067717153\n",
      "Inf_band\n",
      "12.9635350384535\n",
      "Exp20_Close\n",
      "13.594538432577188\n",
      "Subtract_band\n",
      "0.2771442573159134\n",
      "RSI\n",
      "66.96050603091012\n",
      "Total Revenue (TTM)\n",
      "16763000.0\n",
      "Selling General and Administrative Expenses (TTM)\n",
      "4830000.0\n",
      "Total Operating Expenses (TTM)\n",
      "6033000.0\n",
      "Interest Expense (TTM)\n",
      "760000.0\n",
      "Income Before Tax (TTM)\n",
      "10730000.0\n",
      "Income Tax Expense (TTM)\n",
      "161000.0\n",
      "Income from Coninuing Operations (TTM)\n",
      "10569000.0\n",
      "Net Income (TTM)\n",
      "10312000.0\n",
      "Net Income available to Shareholders (TTM)\n",
      "10312000.0\n",
      "High\n",
      "12.699999809265137\n",
      "Low\n",
      "12.079999923706055\n",
      "Open\n",
      "12.109999656677246\n",
      "Close\n",
      "12.649999618530273\n",
      "Volume\n",
      "25162700.0\n",
      "Adj Close\n",
      "11.725982666015625\n",
      "Close_MA\n",
      "11.130927276611327\n",
      "Sup_band\n",
      "11.596645621719079\n",
      "Inf_band\n",
      "10.665208931503576\n",
      "Exp20_Close\n",
      "11.082832602511147\n",
      "Subtract_band\n",
      "0.23285917255387534\n",
      "RSI\n",
      "65.28674417004197\n",
      "Total Revenue (TTM)\n",
      "15907000.0\n",
      "Selling General and Administrative Expenses (TTM)\n",
      "5300000.0\n",
      "Total Operating Expenses (TTM)\n",
      "6088000.0\n",
      "Interest Expense (TTM)\n",
      "nan\n",
      "Income Before Tax (TTM)\n",
      "9819000.0\n",
      "Income Tax Expense (TTM)\n",
      "109000.0\n",
      "Income from Coninuing Operations (TTM)\n",
      "9710000.0\n",
      "Net Income (TTM)\n",
      "9436000.0\n",
      "Net Income available to Shareholders (TTM)\n",
      "9381000.0\n",
      "High\n",
      "10.027299880981445\n",
      "Low\n",
      "9.863639831542969\n",
      "Open\n",
      "9.881819725036621\n",
      "Close\n",
      "10.027299880981445\n",
      "Volume\n",
      "14040950.0\n",
      "Adj Close\n",
      "8.578296661376953\n",
      "Close_MA\n",
      "8.303349208831786\n",
      "Sup_band\n",
      "8.616005262816456\n",
      "Inf_band\n",
      "7.990693154847117\n",
      "Exp20_Close\n",
      "8.35095906668848\n",
      "Subtract_band\n",
      "0.15632802699233483\n",
      "RSI\n",
      "62.99548031773996\n",
      "Total Revenue (TTM)\n",
      "14086000.0\n",
      "Selling General and Administrative Expenses (TTM)\n",
      "4715000.0\n",
      "Total Operating Expenses (TTM)\n",
      "5722000.0\n",
      "Interest Expense (TTM)\n",
      "nan\n",
      "Income Before Tax (TTM)\n",
      "8364000.0\n",
      "Income Tax Expense (TTM)\n",
      "-158000.0\n",
      "Income from Coninuing Operations (TTM)\n",
      "8522000.0\n",
      "Net Income (TTM)\n",
      "8403000.0\n",
      "Net Income available to Shareholders (TTM)\n",
      "8357000.0\n",
      "High\n",
      "7.450699806213379\n",
      "Low\n",
      "7.369420051574707\n",
      "Open\n",
      "7.4055399894714355\n",
      "Close\n",
      "7.414569854736328\n",
      "Volume\n",
      "4589559.0\n",
      "Adj Close\n",
      "6.133592128753662\n",
      "Close_MA\n",
      "5.896599459648132\n",
      "Sup_band\n",
      "6.1906622081670974\n",
      "Inf_band\n",
      "5.602536711129167\n",
      "Exp20_Close\n",
      "5.9693139297825155\n",
      "Subtract_band\n",
      "0.1470313742594825\n",
      "RSI\n",
      "57.13742398851912\n",
      "Total Revenue (TTM)\n",
      "13339000.0\n",
      "Selling General and Administrative Expenses (TTM)\n",
      "4784000.0\n",
      "Total Operating Expenses (TTM)\n",
      "5302000.0\n",
      "Interest Expense (TTM)\n",
      "nan\n",
      "Income Before Tax (TTM)\n",
      "8037000.0\n",
      "Income Tax Expense (TTM)\n",
      "-179000.0\n",
      "Income from Coninuing Operations (TTM)\n",
      "8216000.0\n",
      "Net Income (TTM)\n",
      "8211000.0\n",
      "Net Income available to Shareholders (TTM)\n",
      "8165000.0\n"
     ]
    }
   ],
   "source": [
    "for date in dates:\n",
    "    for column in df.columns:\n",
    "        print(column)\n",
    "        print(df[f'{column}'].loc[date])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
